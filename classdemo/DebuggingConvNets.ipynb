{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging AlexNet and ResNet\n",
        "\n",
        "Covering a few counterintuitive things about real-world networks in practice.\n",
        "* Why is my network very inaccurate?\n",
        "* How to debug a network step-by-step.\n",
        "* Where is my softmax?\n",
        "* Why does it always have `grad_fn`?\n",
        "* Are deeper networks bigger?\n"
      ],
      "metadata": {
        "id": "9cBVIQJ-5omV"
      },
      "id": "9cBVIQJ-5omV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show setup code"
      ],
      "metadata": {
        "id": "gfyG2Vvo5QGh"
      },
      "id": "gfyG2Vvo5QGh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7198984f",
      "metadata": {
        "id": "7198984f"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# If you are on Google Colab, this sets up everything needed.\n",
        "# If not, you will want to pip install the cs7150lib as shown below.\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "pip install git+https://github.com/cs7150/cs7150lib@main\n",
        "\n",
        "wget -N https://cs7150.baulab.info/2022-Fall/data/dog-and-cat-example.jpg\n",
        "wget -N https://cs7150.baulab.info/2022-Fall/data/hungry-cat.jpg\n",
        "wget -N https://cs7150.baulab.info/2022-Fall/data/imagenet-labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501439c7",
      "metadata": {
        "id": "501439c7"
      },
      "source": [
        "\n",
        "This defines some visualization functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f29b82",
      "metadata": {
        "id": "34f29b82"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "from torchvision.models import alexnet, resnet18\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from baukit import ImageFolderSet, show, renormalize, set_requires_grad\n",
        "from torchvision.datasets.utils import download_and_extract_archive\n",
        "\n",
        "if not os.path.isdir('imagenet10k'):\n",
        "    download_and_extract_archive('https://cs7150.baulab.info/2022-Fall/data/imagenet10k.zip', 'imagenet10k')\n",
        "\n",
        "def rgb_heatmap(\n",
        "    data,\n",
        "    size=None,\n",
        "    colormap=\"hot\",\n",
        "    amax=None,\n",
        "    amin=None,\n",
        "    mode=\"bicubic\",\n",
        "    symmetric=False,\n",
        "):\n",
        "    size = spec_size(size)\n",
        "    mapping = getattr(cm, colormap)\n",
        "    scaled = torch.nn.functional.interpolate(data[None, None], size=size, mode=mode)[\n",
        "        0, 0\n",
        "    ]\n",
        "    if amax is None:\n",
        "        amax = data.max()\n",
        "    if amin is None:\n",
        "        amin = data.min()\n",
        "    if symmetric:\n",
        "        amax = max(amax, -amin)\n",
        "        amin = min(amin, -amax)\n",
        "    normed = (scaled - amin) / (amax - amin + 1e-10)\n",
        "    return PIL.Image.fromarray((255 * mapping(normed)).astype(\"uint8\"))\n",
        "\n",
        "\n",
        "def rgb_threshold(data, size=None, mode=\"bicubic\", p=0.2):\n",
        "    size = spec_size(size)\n",
        "    scaled = torch.nn.functional.interpolate(data[None, None], size=size, mode=mode)[\n",
        "        0, 0\n",
        "    ]\n",
        "    ordered = scaled.view(-1).sort()[0]\n",
        "    threshold = ordered[int(len(ordered) * (1 - p))]\n",
        "    result = numpy.tile((scaled > threshold)[:, :, None], (1, 1, 3))\n",
        "    return PIL.Image.fromarray((255 * result).astype(\"uint8\"))\n",
        "\n",
        "\n",
        "def overlay(im1, im2, alpha=0.5):\n",
        "    import numpy\n",
        "\n",
        "    return PIL.Image.fromarray(\n",
        "        (\n",
        "            numpy.array(im1)[..., :3] * alpha + numpy.array(im2)[..., :3] * (1 - alpha)\n",
        "        ).astype(\"uint8\")\n",
        "    )\n",
        "\n",
        "\n",
        "def overlay_threshold(im1, im2, alpha=0.5):\n",
        "    import numpy\n",
        "\n",
        "    return PIL.Image.fromarray(\n",
        "        (\n",
        "            numpy.array(im1)[..., :3] * (1 - numpy.array(im2)[..., :3] / 255) * alpha\n",
        "            + numpy.array(im2)[..., :3] * (numpy.array(im1)[..., :3] / 255)\n",
        "        ).astype(\"uint8\")\n",
        "    )\n",
        "\n",
        "\n",
        "def spec_size(size):\n",
        "    if isinstance(size, int):\n",
        "        dims = (size, size)\n",
        "    if isinstance(size, torch.Tensor):\n",
        "        size = size.shape[:2]\n",
        "    if isinstance(size, PIL.Image.Image):\n",
        "        size = (size.size[1], size.size[0])\n",
        "    if size is None:\n",
        "        size = (224, 224)\n",
        "    return size\n",
        "\n",
        "\n",
        "def resize_and_crop(im, d):\n",
        "    if im.size[0] >= im.size[1]:\n",
        "        im = im.resize((int(im.size[0] / im.size[1] * d), d))\n",
        "        return im.crop(((im.size[0] - d) // 2, 0, (im.size[0] + d) // 2, d))\n",
        "    else:\n",
        "        im = im.resize((d, int(im.size[1] / im.size[9] * d)))\n",
        "        return im.crop((0, (im.size[1] - d) // 2, d, (im.size[1] + d) // 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03361957",
      "metadata": {
        "id": "03361957"
      },
      "source": [
        "## 1. Load a pretrained alexnet\n",
        "\n",
        "The code below loads a pretrained Alexnet, the famous network by Alex Krizhevsky in 2012.\n",
        "\n",
        "Examine the network's layers.  Notice that net.features is a stack of convolutions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e367d3",
      "metadata": {
        "scrolled": false,
        "id": "82e367d3"
      },
      "outputs": [],
      "source": [
        "anet = alexnet(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Run a single image through alexnet\n",
        "\n",
        "First, load the first image in the training set"
      ],
      "metadata": {
        "id": "_Ei5QAJBn_l1"
      },
      "id": "_Ei5QAJBn_l1"
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = Compose([\n",
        "    ToTensor(),\n",
        "    Resize(227),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "ds = ImageFolderSet('imagenet10k/train', transform=preprocess, classification=True, shuffle=True)\n",
        "image_tensor = ds[0][0]\n",
        "\n",
        "show(renormalize.as_image(image_tensor, source=ds))\n",
        "print('shape', image_tensor.shape)"
      ],
      "metadata": {
        "id": "Z0J91k3JnjEf"
      },
      "id": "Z0J91k3JnjEf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then run it through the network.  Try repeating this several times."
      ],
      "metadata": {
        "id": "NFNOGdvHoqp2"
      },
      "id": "NFNOGdvHoqp2"
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch = image_tensor[None]\n",
        "output = anet(input_batch)\n",
        "value, index = output.max(dim=1)\n",
        "print('Predicted class', index, ds.classes[index])\n",
        "print('Predicted value', value)"
      ],
      "metadata": {
        "id": "lZE7G6vaooZS"
      },
      "id": "lZE7G6vaooZS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions to discuss\n",
        "\n",
        "* Is the network outputting a probability?  How can I tell?\n",
        "* What if I want one?\n",
        "* What is the `grad_fn` business?  Do I want it?  When would I want it?\n",
        "* Does the network answer the same answer each time?\n",
        "\n",
        "## Let's fix it\n",
        "1. Go through all the parameters of the network and mark them as `requires_grad=False`.\n",
        "2. Debug the nondeterminism by running the first half of the network and then the second half and then figuring out which layer is messing us up.\n",
        "3. Put the network in the right mode to fix the problem.\n",
        "4. Finally, put a softmax around the whole thing.  Do we need the softmax to measure accuracy?\n"
      ],
      "metadata": {
        "id": "kvaJlcNtpZQp"
      },
      "id": "kvaJlcNtpZQp"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UWphUsMUqiwE"
      },
      "id": "UWphUsMUqiwE"
    },
    {
      "cell_type": "markdown",
      "id": "5bd88c7b",
      "metadata": {
        "id": "5bd88c7b"
      },
      "source": [
        "## 3. Test the accuracy of alexnet\n",
        "\n",
        "The code below downloads a small sample of imagenet and tests the accuracy of alexnet on it.\n",
        "\n",
        "It shows the first 12 examples.  How does it do?\n",
        "\n",
        " 1. Modify the code (remove the \"break\") so that it tests all 10k training examples. Speed things up by using the gpu/tpu.\n",
        " 2. Now modify the code (change from the \"/train\" directory to the \"/val\" directory) to test it on held-out examples.\n",
        "\n",
        "What is your impression of the accuracy of the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57bb74b9",
      "metadata": {
        "id": "57bb74b9"
      },
      "outputs": [],
      "source": [
        "from baukit import pbar\n",
        "\n",
        "examples = []\n",
        "correct = 0\n",
        "tested = 0\n",
        "for i, (im, label) in enumerate(pbar(ds)):\n",
        "    pred = anet(im[None]).argmax(1).item()\n",
        "    if len(examples) < 12:\n",
        "        examples.append([\n",
        "            f'pred: {ds.classes[pred]}',\n",
        "            f'true: {ds.classes[label]}',\n",
        "            [renormalize.as_image(im, source=ds)]])\n",
        "        if len(examples) == 12:\n",
        "            show(show.WRAP, *[examples])\n",
        "            break\n",
        "    tested += 1\n",
        "    if pred == label:\n",
        "        correct += 1\n",
        "\n",
        "print('correct:', correct, 'out of', tested)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Now compare it with resnet"
      ],
      "metadata": {
        "id": "XZOFI5dBr-bA"
      },
      "id": "XZOFI5dBr-bA"
    },
    {
      "cell_type": "code",
      "source": [
        "rnet = resnet18(pretrained=True)\n",
        "rnet"
      ],
      "metadata": {
        "id": "176SDZC3soqg"
      },
      "id": "176SDZC3soqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Things to discuss\n",
        "* This is resnet18.  Is it larger or smaller than AlexNet?\n",
        "* Which one took longer to download?  Why?  Let's write the code to figure it out, like this:\n",
        "\n",
        "```\n",
        "num_params = 0\n",
        "for n, t in anet.named_parameters():\n",
        "    print(n, t.shape, 'param count:', t.numel())\n",
        "    num_params += t.numel()\n",
        "print('total params:', num_params)\n",
        "```\n",
        "\n",
        "Now let's try measuring the accuracy.  Run the code below.\n",
        "\n",
        "* Isn't resnet supposed to be newer?  Why is it always wrong?\n",
        "* Let's debug it.\n",
        "* What input size is resnet supposed to have?  Let's fix it."
      ],
      "metadata": {
        "id": "YTC9mN7as7MK"
      },
      "id": "YTC9mN7as7MK"
    },
    {
      "cell_type": "code",
      "source": [
        "examples = []\n",
        "correct = 0\n",
        "tested = 0\n",
        "for i, (im, label) in enumerate(pbar(ds)):\n",
        "    pred = rnet(im[None]).argmax(1).item()\n",
        "    if len(examples) < 12:\n",
        "        examples.append([\n",
        "            f'pred: {ds.classes[pred]}',\n",
        "            f'true: {ds.classes[label]}',\n",
        "            [renormalize.as_image(im, source=ds)]])\n",
        "        if len(examples) == 12:\n",
        "            show(show.WRAP, *[examples])\n",
        "            break\n",
        "    tested += 1\n",
        "    if pred == label:\n",
        "        correct += 1\n",
        "\n",
        "print('correct:', correct, 'out of', tested)"
      ],
      "metadata": {
        "id": "7mfFAPeytICC"
      },
      "id": "7mfFAPeytICC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fde1e322",
      "metadata": {
        "id": "fde1e322"
      },
      "source": [
        "## 5. Do a sliding window heatmap of alexnet's and resnet salience.\n",
        "\n",
        "Here we will construct a new example by hand, if enough time, using Matt Zeiler's masking salience technique.\n",
        "\n",
        "Try it with resnet also.  What do you have to fix?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imgnum = 3\n",
        "img, target_class = ds[imgnum]\n",
        "pred = net(img[None]).argmax(1).item()\n",
        "show(renormalize.as_image(img, source=ds))\n",
        "print('shape', img.shape)\n",
        "print('pred:', ds.classes[pred], pred)\n",
        "print('true:', ds.classes[target_class], target_class)\n",
        "\n",
        "total_pred = torch.zeros(227, 227)\n",
        "total_true = torch.zeros(227, 227)\n",
        "weight = torch.zeros(227, 227)\n",
        "set_requires_grad(False, net)\n",
        "for y in range(0, 227, 8):\n",
        "    for x in range(0, 227, 8):\n",
        "        inp = img.clone()\n",
        "        inp[:, y:y+32, x:x+32] = 0\n",
        "        #out = torch.nn.functional.softmax(net(inp[None]), dim=1)\n",
        "        out = anet(inp[None])\n",
        "        # print(y, x, out[0, target_class])\n",
        "        total_pred[y:y+32, x:x+32] += out[0, pred]\n",
        "        total_true[y:y+32, x:x+32] += out[0, target_class]\n",
        "        weight[y:y+32, x:x+32] += 1\n",
        "\n",
        "heatmap_pred = (total_pred / weight)\n",
        "heatmap_pred = heatmap_pred - heatmap_pred.min()\n",
        "heatmap_pred = heatmap_pred / heatmap_pred.max() * -2 + 1\n",
        "\n",
        "heatmap_true = (total_true / weight)\n",
        "heatmap_true = heatmap_true - heatmap_true.min()\n",
        "heatmap_true = heatmap_true / heatmap_true.max() * -2 + 1\n",
        "\n",
        "show([[\n",
        "    ['input', [renormalize.as_image(img, source=ds)]],\n",
        "    [ds.classes[pred], [renormalize.as_image(heatmap_pred[None])]],\n",
        "    [ds.classes[target_class], [renormalize.as_image(heatmap_true[None])]]\n",
        "    ]])"
      ],
      "metadata": {
        "id": "LTdSU9Hz0pVs"
      },
      "id": "LTdSU9Hz0pVs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a55ca064",
      "metadata": {
        "id": "a55ca064"
      },
      "source": [
        "## 6. Try running resnet layers\n",
        "\n",
        "Try running resnet layers one-at-a-time and making one channel very large partway through.\n",
        "\n",
        "How does it behave?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RpkJtGLwj1N"
      },
      "id": "0RpkJtGLwj1N",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}