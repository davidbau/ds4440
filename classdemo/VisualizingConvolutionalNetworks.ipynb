{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# If you are on Google Colab, this sets up everything needed.\n",
    "# If not, you will want to pip install the cs7150lib as shown below.\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "pip install git+https://github.com/cs7150/cs7150lib@main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501439c7",
   "metadata": {},
   "source": [
    "# Examining and visualizing convolutions\n",
    "\n",
    "First we just define a widget that will be used for future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f29b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from torchvision.models import alexnet\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from baukit import ImageFolderSet, show, renormalize, set_requires_grad\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "from cs7150 import ConvolutionWidget, ConvolutionNetWidget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962f35d",
   "metadata": {},
   "source": [
    "# 1. Make vertical striped array of numbers\n",
    "\n",
    "Add a line of code below so that vdata contains a circle of vertical stripes, like this:\n",
    "```\n",
    "sdata = torch.tensor([[\n",
    "    [1.0 if i % 3 == 0 else -1.0 for i in range(32)]\n",
    "    for _ in range(32)]])\n",
    "mdata = torch.tensor([[\n",
    "    [1.0 if (i**2 + j**2 < 12**2) else 0.0 for j in range(-16, 16)]\n",
    "    for i in range(-16, 16)]])\n",
    "vdata = sdata * mdata    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4784fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "vdata = torch.zeros(1, 32, 32)\n",
    "# TODO: ADD YOUR CODE HERE.\n",
    "print(vdata[:8,:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ecf5a",
   "metadata": {},
   "source": [
    "# 2. See the interaction with a convolution\n",
    "\n",
    "Click on middle \"convolution\" widget below, and see how the vertical stripe data interacts with a convolution.\n",
    "\n",
    "1. Adjust the convolution to be a vertical edge detector (with a vertical stripe).  What is the result?\n",
    "\n",
    "2. Adjust the convolution to be a horizontal edge detector (with a horizontal stripe).  What happens?\n",
    "\n",
    "After you have created a horizontal edge detector that is blind to the vertical edges, now click on the image to interrupt the purely vertical lines.  What effect do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = ConvolutionWidget(vdata, kernel_size=3)\n",
    "show(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388687b5",
   "metadata": {},
   "source": [
    "## 3. Modify the convolution in code\n",
    "\n",
    "Modify the code below to alter the convolution in the widget above.\n",
    "Use the code to make a horizontal edge-detector with row weights [-0.5, 1.0, -0.5].\n",
    "\n",
    "Why does the convolution weight have four dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21228e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add some code here\n",
    "widget.net[0].weight[0,0,1,:] = 1.0\n",
    "print(widget.net[0].weight)\n",
    "widget.redraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f454a",
   "metadata": {},
   "source": [
    "## 4. Experiment with a stack of two convolutions\n",
    "\n",
    "The code below provides a stack of two convolutions.\n",
    "\n",
    "If you stack a vertical edge detector after a horizontal edge detctor, what will it detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvolutionWidget(vdata, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa869e",
   "metadata": {},
   "source": [
    "## 5. Make a single-dot piece of data\n",
    "\n",
    "Now the array `ddata` should be 1x32x32, and it should be which is -1 everywhere but 1 in the center location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba872ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "ddata = torch.ones(1, 32, 32) * -1\n",
    "# TODO: ADD YOUR CODE HERE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69497d7",
   "metadata": {},
   "source": [
    "## 6. Visualize the effect of a stack of convolutions on a single dot.\n",
    "\n",
    "Now visualize the downstream pixels that are affected by the dot.\n",
    "\n",
    "* Try varying the convolution patterns.  What is the biggest area that you can affect?  This is the inverse of the receptive field.  The receptive field asks \"what is the biggest area that can affect a single pixel in the output\" which is a similar shape, but in the input.\n",
    "\n",
    "* Try varying the `kernel_size` and the `depth`.  What affect does it have on the inverse receptive field?\n",
    "\n",
    "* Do you notice any edge effects?  Why do these appear?  What happens if you change the padding?\n",
    "\n",
    "Once you have played with this, look at the difference between left, right, bottom, and top when you adjust the convolutions:\n",
    "\n",
    "* Did you notice that the coordinates for convolutions are inverted from image coordinates?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c23ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvolutionWidget(ddata, kernel_size=3, depth=3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e95215",
   "metadata": {},
   "source": [
    "## 7. Visualize the receptive field of a stack of convolutions\n",
    "\n",
    "Read and understand the code below....\n",
    "\n",
    "Experiment with a different stack of convolutions.  What does it tell you about the receptive field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870411d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import show, renormalize\n",
    "from torch.nn import Sequential, Conv2d\n",
    "import torch\n",
    "from cs7150 import sliding_window\n",
    "\n",
    "with torch.no_grad():\n",
    "    net = Sequential(\n",
    "        Conv2d(1, 1, kernel_size=3, padding=1, bias=False),\n",
    "        Conv2d(1, 1, kernel_size=3, padding=1, bias=False),\n",
    "    )\n",
    "\n",
    "    heatmap = torch.zeros(32, 32)\n",
    "    for inp in sliding_window(heatmap):\n",
    "        out = net(inp[None])[0,16,16]\n",
    "        heatmap += inp * out * 30\n",
    "\n",
    "    show(show.style(width=150, imageRendering='pixelated'), renormalize.as_image(heatmap[None]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03361957",
   "metadata": {},
   "source": [
    "## 8. Load a pretrained alexnet\n",
    "\n",
    "The code below loads a pretrained Alexnet, the famous network by Alex Krizhevsky in 2012.\n",
    "\n",
    "Examine the network's layers.  Notice that net.features is a stack of convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e367d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = alexnet(pretrained=True)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd88c7b",
   "metadata": {},
   "source": [
    "## 9. Test the accuracy of alexnet\n",
    "\n",
    "The code below downloads a small sample of imagenet and tests the accuracy of alexnet on it.\n",
    "\n",
    "It shows the first 12 examples.  How does it do?\n",
    "\n",
    " 1. Modify the code (remove the \"break\") so that it tests all 10k training examples.\n",
    " 2. Now modify the code (change from the \"/train\" directory to the \"/val\" directory) to test it on held-out examples.\n",
    "\n",
    "What is your impression of the accuracy of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import pbar\n",
    "if not os.path.isdir('imagenet10k'):\n",
    "    download_and_extract_archive('https://cs7150.baulab.info/2022-Fall/data/imagenet10k.zip', 'imagenet10k')\n",
    "preprocess = Compose([\n",
    "    ToTensor(),\n",
    "    Resize(227),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "ds = ImageFolderSet('imagenet10k/train', transform=preprocess, classification=True, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    examples = []\n",
    "    correct = 0\n",
    "    tested = 0\n",
    "    for i, (im, label) in enumerate(pbar(ds)):\n",
    "        pred = net(im[None]).argmax(1).item()\n",
    "        if len(examples) < 12:\n",
    "            examples.append([\n",
    "                f'pred: {ds.classes[pred]}',\n",
    "                f'true: {ds.classes[label]}',\n",
    "                [renormalize.as_image(im, source=ds)]])\n",
    "            if len(examples) == 12:\n",
    "                show(show.WRAP, *[examples])\n",
    "                break\n",
    "        tested += 1\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "print('correct:', correct, 'out of', tested)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90edbd7f",
   "metadata": {},
   "source": [
    "## 10. Explore the convolutional stack of alexnet\n",
    "\n",
    "The widget below runs the `features` subnetwork of alexnet on the first dataset example,\n",
    "and shows the image data as it passes through.\n",
    "\n",
    "Since each layer deals with many channels of data, each box shows the number of possible channels.\n",
    "\n",
    "(Note that the maximum channel numbers are 2, 63, 191, 383, 255, 255 - you can read these sizes out of the  network printout below.)\n",
    "\n",
    "Explore the different channels of alexnet filters.  Can you find any dilters that look like edge-detectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = alexnet(pretrained=True)\n",
    "w = ConvolutionNetWidget(ds[0][0], net=net.features)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1e322",
   "metadata": {},
   "source": [
    "## 11. Extra: we will do a sliding window heatmap of alexnet's salience.\n",
    "\n",
    "Here we will construct a new example by hand, if enough time, using Matt Zeiler's masking salience technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ca064",
   "metadata": {},
   "source": [
    "## 12. Explore alexnet using Polo Chan's CNN explainer\n",
    "\n",
    "Once you're done exploring in pytorch, you can visit the following fancy javascript widget, that lets you interact with alexnet with a pretty UI running inside javascript:\n",
    "\n",
    "https://poloclub.github.io/cnn-explainer/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
