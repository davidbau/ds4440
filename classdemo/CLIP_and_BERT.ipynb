{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3U6Ny2izOkhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIP\n",
        "\n",
        "Using a pretrained clip for zero-shot classification."
      ],
      "metadata": {
        "id": "04litXAS8Qun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7muxb8jFCFz7"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import requests\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# URLs for cat and dog images\n",
        "cat_url = \"https://ds4440.baulab.info/data/cat.png\"\n",
        "dog_url = \"https://ds4440.baulab.info/data/dog.png\"\n",
        "\n",
        "# Download and preprocess the images\n",
        "def preprocess_image(url):\n",
        "    image = Image.open(requests.get(url, stream=True).raw)\n",
        "    image = image.resize((224, 224))\n",
        "    # display the image\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    return inputs\n",
        "\n",
        "# Prepare the text inputs, one for each class\n",
        "cat_text = \"a photo of a cat\"\n",
        "dog_text = \"a photo of a dog\"\n",
        "text_inputs = processor(text=[cat_text, dog_text], padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Get the text features\n",
        "text_features = model.get_text_features(\n",
        "    input_ids=text_inputs[\"input_ids\"],\n",
        "    attention_mask=text_inputs[\"attention_mask\"]\n",
        ")\n",
        "\n",
        "# For each image, get the image features and check similarity with the text\n",
        "for url in [cat_url, dog_url]:\n",
        "    inputs = preprocess_image(url)\n",
        "    image_features = model.get_image_features(pixel_values=inputs[\"pixel_values\"])\n",
        "\n",
        "    # Compute the similarity scores\n",
        "    cat_similarity = (image_features @ text_features.T).squeeze()[0].item()\n",
        "    dog_similarity = (image_features @ text_features.T).squeeze()[1].item()\n",
        "\n",
        "    # Print the similarity scores\n",
        "    print(f\"Cat Similarity: {cat_similarity}\")\n",
        "    print(f\"Dog Similarity: {dog_similarity}\")\n",
        "\n",
        "    # Classify the image based on the higher similarity score\n",
        "    if cat_similarity > dog_similarity:\n",
        "        print(\"The image is classified as a cat.\")\n",
        "    else:\n",
        "        print(\"The image is classified as a dog.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT\n",
        "\n",
        "A brief demonstration of fine-tuning a sentence representation on a problem."
      ],
      "metadata": {
        "id": "bK2S-68XXsR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install torch transformers datasets"
      ],
      "metadata": {
        "id": "2Kp0gcjhXqLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Load the SST-2 dataset\n",
        "dataset = load_dataset('glue', 'sst2')\n",
        "\n",
        "# Load the BERT tokenizer and model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Freeze the BERT model parameters\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Preprocess the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['sentence'], truncation=True)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Collate function to dynamically pad sequences in a batch\n",
        "def collate_fn(batch):\n",
        "    input_ids = [torch.tensor(item['input_ids']) for item in batch]\n",
        "    attention_mask = [torch.tensor(item['attention_mask']) for item in batch]\n",
        "    labels = torch.tensor([item['label'] for item in batch])\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True)\n",
        "    attention_mask = pad_sequence(attention_mask, batch_first=True)\n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
        "\n",
        "# Create DataLoaders with collate function\n",
        "train_dataloader = DataLoader(encoded_dataset['train'], batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "eval_dataloader = DataLoader(encoded_dataset['validation'], batch_size=64, collate_fn=collate_fn)\n",
        "\n",
        "# Set up optimizer and learning rate\n",
        "optimizer = AdamW(model.classifier.parameters(), lr=2e-5)\n",
        "\n",
        "# Fine-tune the classifier part of the model\n",
        "model.classifier.train()\n",
        "model.bert.eval()\n",
        "num_epochs = 1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "progress_bar = tqdm(range(num_epochs * len(train_dataloader)), desc=\"Training\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    epoch_length = 0\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_length += 1\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix({\"Epoch\": epoch+1, \"Loss\": epoch_loss / epoch_length})\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {epoch_loss / epoch_length:.4f}\")\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluation\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "sY4IjR8OUfxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate student-defined examples\n",
        "student_examples = [\n",
        "    \"This movie was predictably amazing.\",\n",
        "    \"The movie was amazingly predictable.\",\n",
        "    \"But I didn't enjoy the book at all.\",\n",
        "    \"All didn't enjoy the book, but I did.\",\n",
        "]\n",
        "\n",
        "student_inputs = tokenizer(student_examples, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**student_inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "# Print the predictions\n",
        "for example, prediction in zip(student_examples, predictions):\n",
        "    sentiment = \"Positive\" if prediction.item() == 1 else \"Negative\"\n",
        "    print(f\"Example: {example}\")\n",
        "    print(f\"Predicted Sentiment: {sentiment}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "RxLWivFX8Jce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}