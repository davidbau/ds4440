{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial attack\n",
        "\n",
        "Question: what does it take to turn a little dog into a pineapple?"
      ],
      "metadata": {
        "id": "O5t7s_eqRo2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -r \"https://ds4440.baulab.info/data/dog.png\"\n",
        "!wget -r \"https://ds4440.baulab.info/data/imagenet_class_index.json\""
      ],
      "metadata": {
        "id": "pMBTMAyalwkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpGBf6c7lt6I"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import requests\n",
        "from torchvision.utils import save_image\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "\n",
        "# Load the names of imagenet classes\n",
        "with open(\"imagenet_class_index.json\") as f:\n",
        "    class_idx = json.load(f)\n",
        "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
        "\n",
        "# Load pretrained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# We will NOT train this model!\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "class UnNormalize(transforms.Normalize):\n",
        "    def __init__(self, mean, std, *args,**kwargs):\n",
        "        new_mean = [-m/s for m,s in zip(mean,std)]\n",
        "        new_std = [1/s for s in std]\n",
        "        super().__init__(new_mean, new_std, *args, **kwargs)\n",
        "\n",
        "# Preprocessing transform\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "black = preprocess.transforms[-1](torch.tensor([[[-1.0]], [[-1.0]], [[-1.0]]]))\n",
        "white = preprocess.transforms[-1](torch.tensor([[[1.0]], [[1.0]], [[1.0]]]))\n",
        "\n",
        "unprocess = transforms.Compose([\n",
        "    UnNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.ToPILImage(),\n",
        "])\n",
        "\n",
        "# Load and preprocess image\n",
        "img = Image.open(\"dog.png\").convert('RGB')\n",
        "input_tensor = preprocess(img)\n",
        "\n",
        "# PGD Attack\n",
        "def pgd_attack(image, model, target_class, epsilon=0.01, alpha=0.01, num_steps=10):\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Clone the image\n",
        "    image = image.clone()\n",
        "\n",
        "    # Set requires_grad attribute of tensor\n",
        "    image.requires_grad = True\n",
        "\n",
        "    for i in range(num_steps):\n",
        "        # Forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = nn.CrossEntropyLoss()(output, torch.tensor([target_class]))\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Compute a step change in the IMAGE (not the network!)\n",
        "        eta = -alpha * image.grad.sign()\n",
        "\n",
        "        # Project the step to the epislon ball to keep changes small\n",
        "        eta = torch.clamp(eta, -epsilon, epsilon)\n",
        "\n",
        "        # Create the perturbed image by adjusting each pixel of the input image\n",
        "        with torch.no_grad():\n",
        "            image += eta\n",
        "\n",
        "            # Prevent image pixels brighter than white or darker than black\n",
        "            image.clamp_(min=black, max=white)\n",
        "\n",
        "    return image.detach()\n",
        "\n",
        "# Set target class and epsilon\n",
        "target_class = 953  # example target class (pineapple)\n",
        "epsilon = 0.01\n",
        "alpha = 0.01\n",
        "num_steps = 10\n",
        "\n",
        "# Set input tensor\n",
        "input_batch = input_tensor[None].to(device)\n",
        "\n",
        "# Generate adversarial example\n",
        "adversarial_ex = pgd_attack(input_batch, model, target_class, epsilon, alpha, num_steps)[0]\n",
        "\n",
        "# Save original and adversarial images\n",
        "save_image(adversarial_ex, 'adversarial_image.png')\n",
        "\n",
        "# Show the results\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "for i, (im, title) in enumerate([\n",
        "    (input_tensor, 'Original'),\n",
        "    (adversarial_ex, 'Adversarial'),\n",
        "    (input_tensor - adversarial_ex, 'Difference')\n",
        "]):\n",
        "    ax[i].imshow(unprocess(im))\n",
        "    ax[i].axis('off')\n",
        "    ax[i].set_title(title)\n",
        "plt.show()\n",
        "\n",
        "print(\"Original prediction:\", idx2label[model(input_batch).argmax().item()])\n",
        "print(\"Adversarial prediction:\", idx2label[model(adversarial_ex[None]).argmax().item()])\n"
      ]
    }
  ]
}