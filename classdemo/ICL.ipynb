{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers torch\n"
      ],
      "metadata": {
        "id": "o3on-xWbV8tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a2PA1LfQ57C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import required modules\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = \"EleutherAI/gpt-neo-1.3B\"  # You can change this to a different model if desired\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Function to generate text using the model\n",
        "def generate_text(prompt, max_length=20):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=input_ids.size(1) + max_length,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Example ICL prompts\n",
        "examples = [\n",
        "    {\n",
        "        \"name\": \"Translation\",\n",
        "        \"prompt\": \"\"\"\n",
        "Translate the following sentences from English to French:\n",
        "\n",
        "English: Hello, how are you?\n",
        "French: Bonjour, comment allez-vous?\n",
        "\n",
        "English: I love programming.\n",
        "French: J'adore la programmation.\n",
        "\n",
        "English: The weather is nice today.\n",
        "French:\\\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Sentiment Analysis\",\n",
        "        \"prompt\": \"\"\"\n",
        "Determine the sentiment of the following sentences:\n",
        "\n",
        "Sentence: This movie was amazing! I loved every moment of it.\n",
        "Sentiment: Positive\n",
        "\n",
        "Sentence: The food at that restaurant was terrible. I won't be going back.\n",
        "Sentiment: Negative\n",
        "\n",
        "Sentence: The book was okay, but not as good as I expected.\n",
        "Sentiment:\\\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Question Answering\",\n",
        "        \"prompt\": \"\"\"\n",
        "Answer the following questions based on the given context:\n",
        "\n",
        "Context: John is a 12-year-old boy who loves playing soccer. He practices every day after school for an hour. His favorite team is Manchester United, and he dreams of playing for them one day.\n",
        "\n",
        "Question: How old is John?\n",
        "Answer: John is 12 years old.\n",
        "\n",
        "Question: What is John's favorite soccer team?\n",
        "Answer: John's favorite soccer team is Manchester United.\n",
        "\n",
        "Question: How often does John practice soccer?\n",
        "Answer:\\\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Display example prompts\n",
        "print(\"Example ICL Prompts:\")\n",
        "for i, example in enumerate(examples):\n",
        "    print(f\"{i + 1}. {example['name']}:\")\n",
        "    print(example['prompt'])\n",
        "    print()\n",
        "\n",
        "while True:\n",
        "    # Get user input for the prompt and generate text\n",
        "    prompt_choice = int(input(\"Choose an example prompt (1-3) or enter 0 for a custom prompt: \"))\n",
        "    if prompt_choice == 0:\n",
        "        prompt = input(\"Enter your custom prompt: \")\n",
        "    else:\n",
        "        prompt = examples[prompt_choice - 1]['prompt']\n",
        "\n",
        "    generated_text = generate_text(prompt)\n",
        "\n",
        "    # Print the generated text\n",
        "    print(\"Generated Text:\")\n",
        "    print(generated_text[len(prompt):generated_text.find('\\n')])"
      ]
    }
  ]
}